import streamlit as st
import folium
from streamlit_folium import st_folium
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime, timedelta, timezone
import re

# --- è¨­å®š ---
CACHE_TTL = 3600 # 1æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥

st.set_page_config(page_title="ç§‹ç”°çœŒè¿‘è¾ºã‚¹ã‚­ãƒ¼å ´æƒ…å ±", layout="wide")

# --- æ™‚é–“è¨­å®š (JST) ---
JST = timezone(timedelta(hours=9), 'JST')
now_jst = datetime.now(timezone.utc).astimezone(JST)
ACCESS_TIME = now_jst.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
today_str = now_jst.strftime("%m/%d")
tmrw_str = (now_jst + timedelta(days=1)).strftime("%m/%d")

# --- CSS ---
st.markdown("""
<style>
    .table-container { max-height: 600px; overflow: auto; border: 1px solid #ddd; margin-bottom: 30px; }
    table { width: 100%; border-collapse: collapse; font-family: sans-serif; font-size: 13px; white-space: nowrap; }
    th, td { padding: 10px 12px; text-align: left; border-bottom: 1px solid #ddd; }
    thead th { position: sticky; top: 0; background-color: #008CBA; color: white; z-index: 2; }
    th:first-child, td:first-child { position: sticky; left: 0; background-color: #008CBA; z-index: 3; }
    tbody td:first-child { background-color: #fff; z-index: 1; font-weight: bold; border-right: 2px solid #ddd; }
    tbody tr:nth-child(even) { background-color: #f8f9fa; }
    tbody tr:nth-child(even) td:first-child { background-color: #f8f9fa; }
    
    .status-ok { color: green; font-weight: bold; background:#e6fffa; padding:2px 5px; border-radius:4px; }
    .status-ng { color: #d9534f; font-weight: bold; background:#fff5f5; padding:2px 5px; border-radius:4px; }
    .no-data { color: #999; font-size: 0.9em; }
    .link-btn { background: #fff; border: 1px solid #008CBA; color: #008CBA; padding: 2px 8px; border-radius: 4px; text-decoration: none; font-size: 0.8em;}
    .update-info { background:#fff3cd; padding:10px; border-radius:5px; margin-bottom:15px; font-size:0.9em; }
</style>
""", unsafe_allow_html=True)

st.title("â›·ï¸ ç§‹ç”°çœŒè¿‘è¾ºã‚¹ã‚­ãƒ¼å ´ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æƒ…å ±é›†ç´„")
st.markdown(f"##### è‡ªå‹•ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¼·åŒ–ç‰ˆ")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
filter_open_only = st.sidebar.checkbox("å–¶æ¥­ä¸­ã®ã¿è¡¨ç¤º", value=False)

# --- ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•° ---
@st.cache_data(ttl=CACHE_TTL)
def scrape_resort(url, total_courses):
    """
    ã‚µã‚¤ãƒˆã‹ã‚‰ç©é›ªã€çŠ¶æ³ã€ãã—ã¦ã€Œã‚ªãƒ¼ãƒ—ãƒ³ã—ã¦ã„ã‚‹ã‚³ãƒ¼ã‚¹æ•°ã€ã‚’æŠ½å‡ºã™ã‚‹
    """
    data = {
        "snow": "æœªå–å¾—", 
        "status": "ç¢ºèªä¸­", 
        "open_count": "?" # ã‚ªãƒ¼ãƒ—ãƒ³ã‚³ãƒ¼ã‚¹æ•°
    }
    headers = {"User-Agent": "Mozilla/5.0"}
    
    try:
        res = requests.get(url, headers=headers, timeout=5)
        res.encoding = res.apparent_encoding
        if res.status_code == 200:
            soup = BeautifulSoup(res.text, 'html.parser')
            text = soup.get_text().replace('\n', '').replace(' ', '')
            
            # 1. ç©é›ª
            match = re.search(r'(ç©é›ª|å±±é ‚)[:ï¼š]*([0-9]{1,3})cm', text)
            if match: data["snow"] = f"{match.group(2)}cm"
            
            # 2. çŠ¶æ³åˆ¤å®š
            if "å…¨é¢æ»‘èµ°å¯" in text: 
                data["status"] = "âœ… å…¨é¢å¯"
                data["open_count"] = total_courses # å…¨é¢å¯ãªã‚‰å…¨ã‚³ãƒ¼ã‚¹ã‚ªãƒ¼ãƒ—ãƒ³
            elif "ä¸€éƒ¨æ»‘èµ°" in text: 
                data["status"] = "âš ï¸ ä¸€éƒ¨å¯"
                # ã€ŒXã‚³ãƒ¼ã‚¹æ»‘èµ°å¯ã€ã®ã‚ˆã†ãªè¨˜è¿°ã‚’æ¢ã™
                match_c = re.search(r'([0-9]{1,2})([æœ¬|ã‚³ãƒ¼ã‚¹])(æ»‘èµ°|ã‚ªãƒ¼ãƒ—ãƒ³|å¯)', text)
                if match_c:
                    data["open_count"] = int(match_c.group(1))
            elif "å–¶æ¥­ä¸­" in text: 
                data["status"] = "âœ… å–¶æ¥­ä¸­"
                # æ˜è¨˜ãŒãªã„å ´åˆã¯ä¸æ˜ã ãŒã€å–¶æ¥­ä¸­ãªã‚‰ä»®ã«ã€Œ?ã€ã‹ã€ä¸€éƒ¨è¨˜è¿°ã‚’æ¢ã™
                match_c = re.search(r'([0-9]{1,2})([æœ¬|ã‚³ãƒ¼ã‚¹])(æ»‘èµ°|ã‚ªãƒ¼ãƒ—ãƒ³|å¯)', text)
                if match_c:
                    data["open_count"] = int(match_c.group(1))
            elif "æº–å‚™ä¸­" in text: 
                data["status"] = "â›” æº–å‚™ä¸­"
                data["open_count"] = 0
            elif "ã‚¯ãƒ­ãƒ¼ã‚º" in text or "çµ‚äº†" in text: 
                data["status"] = "â›” ã‚¯ãƒ­ãƒ¼ã‚º"
                data["open_count"] = 0
            
    except:
        pass
    return data

# --- ãƒ‡ãƒ¼ã‚¿å®šç¾© (ã‚¹ãƒšãƒƒã‚¯å›ºå®šãƒ‡ãƒ¼ã‚¿) ---
# â€»ã€Œåœ§é›ª/éåœ§é›ªã€ã®å†…è¨³ã‚„ã€Œå…¨ã‚³ãƒ¼ã‚¹æ•°ã€ã¯ç‰©ç†çš„ãªæ–½è¨­æƒ…å ±ã®ãŸã‚å›ºå®šå€¤ã¨ã—ã¦æŒã¡ã¾ã™
base_resorts = [
    {
        "name": "å¤æ²¹é«˜åŸ", "full_name": "å¤æ²¹é«˜åŸã‚¹ã‚­ãƒ¼å ´", "url": "https://www.getokogen.com/", 
        "lat": 39.2178, "lon": 140.9242, "time": 115, "dist": 139, "price": 6800,
        "total": 14, "groom": 10, "ungroom": 4, 
        "yt_id": "Vo9xtIyktUY", "live": "https://www.youtube.com/@getokogen/live"
    },
    {
        "name": "ç§‹ç”°å…«å¹¡å¹³", "full_name": "ç§‹ç”°å…«å¹¡å¹³ã‚¹ã‚­ãƒ¼å ´", "url": "https://www.akihachi.jp/", 
        "lat": 39.9922, "lon": 140.8358, "time": 115, "dist": 105, "price": 4000,
        "total": 4, "groom": 2, "ungroom": 2, 
        "live": "https://www.akihachi.jp/"
    },
    {
        "name": "é˜¿ä»", "full_name": "æ£®å‰å±±é˜¿ä»ã‚¹ã‚­ãƒ¼å ´", "url": "https://www.aniski.jp/", 
        "lat": 39.9575, "lon": 140.4564, "time": 85, "dist": 79, "price": 4500,
        "total": 5, "groom": 3, "ungroom": 2, 
        "live": "https://www.aniski.jp/livecam/"
    },
    {
        "name": "ãŸã–ã‚æ¹–", "full_name": "ãŸã–ã‚æ¹–ã‚¹ã‚­ãƒ¼å ´", "url": "https://www.tazawako-ski.com/", 
        "lat": 39.7567, "lon": 140.7811, "time": 90, "dist": 78, "price": 5300,
        "total": 13, "groom": 9, "ungroom": 4, 
        "live": "http://www.tazawako-ski.com/gelande/"
    },
    {
        "name": "ã‚ªãƒ¼ãƒ‘ã‚¹", "full_name": "å¤ªå¹³å±±ã‚¹ã‚­ãƒ¼å ´ã‚ªãƒ¼ãƒ‘ã‚¹", "url": "http://www.theboon.net/opas/", 
        "lat": 39.7894, "lon": 140.1983, "time": 30, "dist": 22, "price": 2200,
        "total": 5, "groom": 5, "ungroom": 0, 
        "live": "http://www.theboon.net/opas/livecam.html"
    },
    {
        "name": "ã‚¸ãƒ¥ãƒã‚¹æ —é§’", "full_name": "ã‚¸ãƒ¥ãƒã‚¹æ —é§’ã‚¹ã‚­ãƒ¼å ´", "url": "https://jeunesse-ski.com/", 
        "lat": 39.1950, "lon": 140.6922, "time": 95, "dist": 110, "price": 4000,
        "total": 12, "groom": 10, "ungroom": 2, 
        "live": "https://jeunesse-ski.com/live-camera/"
    },
    {
        "name": "çŸ¢å³¶", "full_name": "é³¥æµ·é«˜åŸçŸ¢å³¶ã‚¹ã‚­ãƒ¼å ´", "url": "https://www.yashimaski.com/", 
        "lat": 39.1866, "lon": 140.1264, "time": 85, "dist": 91, "price": 3000,
        "total": 6, "groom": 5, "ungroom": 1, 
        "live": "https://ski.city.yurihonjo.lg.jp/live-camera/"
    },
    {
        "name": "å”å’Œ", "full_name": "å”å’Œã‚¹ã‚­ãƒ¼å ´", "url": "https://kyowasnow.net/", 
        "lat": 39.6384, "lon": 140.3230, "time": 50, "dist": 45, "price": 3300,
        "total": 7, "groom": 7, "ungroom": 0, 
        "live": "https://kyowasnow.net/"
    },
    {
        "name": "èŠ±è¼ª", "full_name": "èŠ±è¼ªã‚¹ã‚­ãƒ¼å ´", "url": "https://www.alpas.jp/", 
        "lat": 40.1833, "lon": 140.7871, "time": 115, "dist": 112, "price": 3400,
        "total": 7, "groom": 7, "ungroom": 0, 
    },
    {
        "name": "æ°´æ™¶å±±", "full_name": "æ°´æ™¶å±±ã‚¹ã‚­ãƒ¼å ´", "url": "https://www.city.shizukuishi.iwate.jp/", 
        "lat": 39.7344, "lon": 140.6275, "time": 90, "dist": 88, "price": 3000,
        "total": 4, "groom": 4, "ungroom": 0, 
    },
    {
        "name": "å¤§å°", "full_name": "å¤§å°ã‚¹ã‚­ãƒ¼å ´", "url": "https://ohdai.omagari-sc.com/", 
        "lat": 39.4625, "lon": 140.5592, "time": 60, "dist": 65, "price": 3100,
        "total": 6, "groom": 6, "ungroom": 0, 
    },
    {
        "name": "å¤©ä¸‹æ£®", "full_name": "å¤©ä¸‹æ£®ã‚¹ã‚­ãƒ¼å ´", "url": "https://www.city.yokote.lg.jp/kanko/1004655/1004664/1001402.html", 
        "lat": 39.2775, "lon": 140.5986, "time": 85, "dist": 95, "price": 2700,
        "total": 2, "groom": 2, "ungroom": 0, 
    },
    {
        "name": "å¤§æ›²ãƒ•ã‚¡ãƒŸãƒªãƒ¼", "full_name": "å¤§æ›²ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚¹ã‚­ãƒ¼å ´", "url": "https://www.city.daisen.lg.jp/docs/2013110300234/", 
        "lat": 39.4283, "lon": 140.5231, "time": 55, "dist": 60, "price": 2400,
        "total": 1, "groom": 1, "ungroom": 0, 
    },
    {
        "name": "ç¨²å·", "full_name": "ç¨²å·ã‚¹ã‚­ãƒ¼å ´", "url": "https://www.city-yuzawa.jp/site/inakawaski/", 
        "lat": 39.0681, "lon": 140.5894, "time": 95, "dist": 105, "price": 2500,
        "total": 2, "groom": 2, "ungroom": 0, 
    }
]

# --- API (å¤©æ°—) ---
@st.cache_data(ttl=3600)
def get_weather():
    res = {}
    for r in base_resorts:
        try:
            url = "https://api.open-meteo.com/v1/forecast"
            p = {"latitude": r["lat"], "longitude": r["lon"], "daily": "weathercode", "timezone": "Asia/Tokyo", "forecast_days": 2}
            d = requests.get(url, params=p, timeout=2).json()
            c1, c2 = d['daily']['weathercode'][0], d['daily']['weathercode'][1]
            w_map = {0:"â˜€ï¸", 1:"ğŸŒ¤ï¸", 2:"â˜ï¸", 3:"â˜ï¸", 45:"ğŸŒ«ï¸", 51:"ğŸŒ§ï¸", 53:"ğŸŒ§ï¸", 55:"ğŸŒ§ï¸", 61:"â˜”", 63:"â˜”", 71:"â˜ƒï¸", 73:"â˜ƒï¸", 75:"â˜ƒï¸", 77:"ğŸŒ¨ï¸", 80:"ğŸŒ¦ï¸", 85:"ğŸŒ¨ï¸", 95:"âš¡"}
            res[r["name"]] = {"t": w_map.get(c1, "-"), "tm": w_map.get(c2, "-")}
        except:
            res[r["name"]] = {"t": "-", "tm": "-"}
    return res

def fmt_time(m):
    return f"{m//60}æ™‚é–“{m%60}åˆ†" if m//60 > 0 else f"{m}åˆ†"

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
st.markdown(f"""
<div class="update-info">
    <b>ğŸ”„ æ›´æ–°çŠ¶æ³ ({ACCESS_TIME})</b><br>
    ç©é›ªãƒ»ã‚ªãƒ¼ãƒ—ãƒ³ã‚³ãƒ¼ã‚¹æ•°ãƒ»å–¶æ¥­çŠ¶æ³ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚µã‚¤ãƒˆã‹ã‚‰å–å¾—ã—ã¦ã„ã¾ã™ã€‚<br>
    <span style="font-size:0.8em">â€»ã€Œã‚ªãƒ¼ãƒ—ãƒ³æ•°ã€ã¯ã‚µã‚¤ãƒˆå†…ã«ã€Œå…¨é¢ã€ã‚„ã€Œ5ã‚³ãƒ¼ã‚¹ã€ç­‰ã®è¨˜è¿°ãŒã‚ã‚‹å ´åˆã®ã¿è‡ªå‹•åæ˜ ã•ã‚Œã¾ã™ã€‚</span>
</div>
""", unsafe_allow_html=True)

progress_bar = st.progress(0, text="ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹...")

# 1. å¤©æ°—
weather = get_weather()
progress_bar.progress(10, text="å¤©æ°—å–å¾—å®Œäº†")

# 2. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° & çµåˆ
df_list = []
cams = []
count = 0
total = len(base_resorts)

for i, r in enumerate(base_resorts):
    progress_bar.progress(10 + int((i/total)*90), text=f"{r['name']} è§£æä¸­...")
    
    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° (å…¨ã‚³ãƒ¼ã‚¹æ•°ã‚’æ¸¡ã—ã¦ã€å…¨é¢å¯ãªã‚‰ãã‚Œã‚’æ¡ç”¨ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯)
    scraped = scrape_resort(r['url'], r['total'])
    
    is_open = "å–¶æ¥­" in scraped["status"] or "å¯" in scraped["status"]
    if filter_open_only and not is_open:
        continue
    
    count += 1
    w = weather.get(r["name"], {"t":"-", "tm":"-"})
    t_winter = int(r["time"] * 1.35)
    
    # è¡¨ç¤ºåŠ å·¥
    status_html = scraped['status']
    if "â›”" in status_html: status_html = f'<span class="status-ng">{status_html}</span>'
    else: status_html = f'<span class="status-ok">{status_html}</span>'
    
    snow_val = scraped['snow']
    if snow_val == "æœªå–å¾—": snow_val = '<span class="no-data">-</span>'
    else: snow_val = f"<b>{snow_val}</b>"

    # ã‚³ãƒ¼ã‚¹æ•°è¡¨ç¤º (ã‚ªãƒ¼ãƒ—ãƒ³æ•° / å…¨æ•°)
    open_val = scraped['open_count']
    if open_val == "?": open_val = '<span class="no-data">?</span>'
    
    course_disp = f"<b>{open_val}</b> / {r['total']}"

    df_list.append({
        "ã‚¹ã‚­ãƒ¼å ´": r["name"],
        "ç©é›ª": snow_val,
        "çŠ¶æ³": status_html,
        "ã‚³ãƒ¼ã‚¹æ•°<br><span style='font-size:0.8em'>(é–‹/å…¨)</span>": course_disp,
        "å†…è¨³<br><span style='font-size:0.8em'>(åœ§é›ª/éåœ§é›ª)</span>": f"{r['groom']} / {r['ungroom']}",
        "ãƒªãƒ•ãƒˆåˆ¸": f"Â¥{r['price']:,}",
        f"å¤©æ°—({today_str})": w['t'],
        "è·é›¢/æ™‚é–“": f"{r['dist']}km/{fmt_time(t_winter)}",
        "ãƒªãƒ³ã‚¯": f'<a href="{r["url"]}" target="_blank" class="link-btn">å…¬å¼HP</a>',
        "lat": r["lat"], "lon": r["lon"], "raw_status": scraped['status'], "full_name": r["full_name"]
    })
    
    if r.get("live"):
        c = r.copy()
        c["status"] = scraped["status"]
        cams.append(c)

progress_bar.empty()

if count == 0:
    st.error("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ã‚¹ã‚­ãƒ¼å ´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    df = pd.DataFrame(df_list)
    
    # 1. ä¸€è¦§
    st.subheader("ğŸ“‹ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çŠ¶æ³ä¸€è¦§")
    html = df.drop(columns=["lat", "lon", "raw_status", "full_name"]).to_html(classes="table", escape=False, index=False)
    st.markdown(f'<div class="table-container">{html}</div>', unsafe_allow_html=True)
    
    # 2. ã‚«ãƒ¡ãƒ©
    st.divider()
    st.subheader("ğŸ“· ãƒ©ã‚¤ãƒ–ã‚«ãƒ¡ãƒ©")
    cols_per_row = 3
    rows = [cams[i:i + cols_per_row] for i in range(0, len(cams), cols_per_row)]
    for row in rows:
        cols = st.columns(cols_per_row)
        for idx, cam in enumerate(row):
            with cols[idx]:
                if cam.get("yt_id"):
                    thumb = f"https://img.youtube.com/vi/{cam['yt_id']}/mqdefault.jpg"
                else:
                    bg = "008CBA" if "å–¶æ¥­" in cam['status'] or "å¯" in cam['status'] else "6c757d"
                    safe_name = cam['name'].replace(" ", "")
                    thumb = f"https://placehold.co/600x338/{bg}/FFFFFF/png?text={safe_name}"
                st.markdown(f"**{cam['name']}**")
                st.markdown(f"[![cam]({thumb})]({cam['live']})")
    
    # 3. ãƒãƒƒãƒ—
    st.divider()
    st.subheader("ğŸ—ºï¸ ãƒãƒƒãƒ—")
    m = folium.Map(location=[39.8, 140.5], zoom_start=9)
    for _, row in df.iterrows():
        c = "red" if "å–¶æ¥­" in row['raw_status'] or "å¯" in row['raw_status'] else "blue"
        folium.Marker(
            [row['lat'], row['lon']], popup=row['full_name'], icon=folium.Icon(color=c, icon="info-sign")
        ).add_to(m)
    st_folium(m, width="100%", height=500)
